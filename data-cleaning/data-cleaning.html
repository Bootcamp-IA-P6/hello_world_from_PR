<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Limpieza y Transformación de Datos</title>
  <link rel="stylesheet" href="data-cleaning.css" />
</head>
<body>
<section id="limpieza" class="content-section">
  <h2>Limpieza & Transformación</h2>

  <p class="intro">
    Es el proceso de detectar y corregir errores en un conjunto de datos. Esto incluye eliminar duplicados, rellenar o manejar valores faltantes, 
    corregir formatos inconsistentes y quitar información incorrecta. Su objetivo es dejar los datos claros, precisos y confiables.
  </p>

  <div class="card-grid">
    
    <!-- CARD 1: DATA WRANGLING -->
    <div class="origin-card">
      <img src="../assets/data-cleaning/dw-dc.jpg" alt="Proceso de limpieza de datos" />
      <div class="card-content">
        <span class="year">Preprocesamiento</span>
        <h3>Data Wrangling y Calidad</h3>
        <p>
          El Data Wrangling consiste en transformar y limpiar datos crudos para hacerlos utilizables. 
          Sin una buena calidad de datos, se aplica el principio "Garbage In, Garbage Out".
        </p>
      </div>
    </div>

    <!-- CARD 2: OUTLIERS (Corregido '1600s' a 'Depuración') -->
    <div class="origin-card">
      <img src="../assets/data-cleaning/outliers.png" alt="Outliers" />
      <div class="card-content">
        <span class="year">Depuración</span>
        <h3>Manejo de valores nulos y outliers</h3>
        <p>
          También se llama depuración de datos. Es el proceso de identificar y corregir errores e incongruencias 
          para garantizar que sean precisos, coherentes y utilizables.
        </p>
      </div>
    </div>

    <!-- CARD 3: ETL/ELT -->
    <div class="origin-card">
      <img src="../assets/data-cleaning/etl-elt-pipeline.webp" alt="etl-elt-pipeline" />
      <div class="card-content">
        <span class="year">Data Cleaning</span>
        <h3>ETL/ELT y Pipelines de Datos</h3>
        <p>
          ETL y ELT son procesos para mover y preparar datos. Un pipeline es la secuencia automatizada 
          que siguen los datos desde su origen hasta su destino, asegurando que lleguen listos para usarse.
        </p>
      </div>
    </div>

    <!-- CARD 4: FEATURE ENGINEERING -->
    <div class="origin-card">
      <img src="../assets/data-cleaning/engineering.png" alt="Feature Engineering" />
      <div class="card-content">
        <span class="year">Ingeniería</span>
        <h3>Feature Engineering</h3>
        <p>
          Proceso de crear, transformar y seleccionar características (features) relevantes a partir de los datos brutos. 
          Esta etapa es crucial para mejorar el rendimiento de los modelos.
        </p>
      </div>
    </div>

    <!-- CARD 5: EDA (Exploratory Data Analysis) -->
    <div class="origin-card">
      <img src="../assets/data-cleaning/DataCleaning.png" alt="EDA" />
      <div class="card-content">
        <span class="year">Análisis</span>
        <h3>Exploratory Data Analysis (EDA)</h3>
        <p>
          Exploratory data analysis helps you understand the structure, patterns, and anomalies in a dataset 
          before building models or drawing conclusions.
        </p>
      </div>
    </div>
  </div>

  <blockquote class="inspiration">
    “Los datos son el nuevo petróleo. Son valiosos, pero si no se refinan, no pueden utilizarse realmente.” — Clive Humby
  </blockquote>
</section>
</body>
</html>